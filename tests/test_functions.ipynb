{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd2b197-51ca-4067-94fa-af00ddace9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "#### IMPORTS ####\n",
    "#################\n",
    "\n",
    "# Arrays\n",
    "import numpy as np\n",
    "\n",
    "# Deep Learning stuff\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Images display and plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fancy progress bars\n",
    "import tqdm.notebook as tq\n",
    "\n",
    "# Tensor Network Stuff\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import quimb.tensor as qtn # Tensor Network library\n",
    "import quimb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6755d698-ef0e-4752-a3b0-42a146f60541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "# My functions\n",
    "from TNutils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6fe56-3014-405a-9f2f-a89959c96b19",
   "metadata": {},
   "source": [
    "### 1. Handling MNIST images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfcd59-a0f9-47cd-b9c0-c66139c7e2e8",
   "metadata": {},
   "source": [
    "Get MNIST data\n",
    "1. Actually download data\n",
    "2. Flatten each image\n",
    "3. Normalize [0,255] -> [0,1]\n",
    "4. Trasform from grayscale to binary images [0,1] -> {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d49cfd-8647-401d-a030-f564e5dbb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516f0e99-9072-43cc-b097-4fac2febd18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: (1000, 784)\n",
      "Shape of the test set:     (100, 784)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the training set: {}'.format(train_set.shape) )\n",
    "print('Shape of the test set:     {}'.format(test_set.shape) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff12766-aed6-4916-a98e-8348cad093b9",
   "metadata": {},
   "source": [
    "Example of an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e310b3-233c-4f20-bffc-92f99c899a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-03-16T10:44:53.621064</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 231.84 \n",
       "L 231.84 231.84 \n",
       "L 231.84 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p856aac3820)\">\n",
       "    <image height=\"218\" id=\"image4e8ae53b92\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAADEElEQVR4nO3dgWnkQBAAQcs4/5T3E3ju8Mnbu5KqIhBYzcANIx9jjPEFTPW9+gHgCYQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBoGf1Q/wynEcqx9hiTHG6kfgj5loEBAaBIQGAaFBQGgQEBoEhAaBY1x4afPUPdtZF/6TX5aJBgGhQUBoEBAaBIQGAaFBYOszmXee+jO1tcb1mGgQEBoEhAYBoUFAaBAQGgSEBoFLn8nwf2f2bF6HOUw0CAgNAkKDgNAgIDQICA0CQoPApe/RZnq3i7Jv4jdMNAgIDQJCg4DQICA0CAgNAkKDgD3ah+5682V/OIeJBgGhQUBoEBAaBIQGAaFBwM/7C/gJ/XlMNAgIDQJCg4DQICA0CAgNAkKDgH/b9KEzZzI78zrMYaJBQGgQEBoEhAYBoUFAaBAQGgTco33o3b7prns2PmOiQUBoEBAaBIQGAaFBQGgQEBoE7NEmebVnm71jc1O2HxMNAkKDgNAgIDQICA0CQoOA0CDgu44bsme7HxMNAkKDgNAgIDQICA0CQoOAM5kH2vVTeGc/4bfz2sJEg4DQICA0CAgNAkKDgNAgIDQIOJO5oF33YLtb+aqbaBAQGgSEBgGhQUBoEBAaBIQGAXs0trF6PzgzBRMNAkKDgNAgIDQICA0CQoOA0CDgu45s4+wea/Ue7hUTDQJCg4DQICA0CAgNAkKDgNAgYI/Gbex8WmmiQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFB4B9iZFagVCZgugAAAABJRU5ErkJggg==\" y=\"-6.64\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p856aac3820\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(train_set[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e0876-76f9-4e07-8501-2b90fade1070",
   "metadata": {},
   "source": [
    "Further on, we will like to get rid parts of the image and reconstruct them.\n",
    "There is a function for partially removing parts of the image in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3630a78e-7d20-443f-8f4e-bd46d2251d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-03-16T10:44:53.686907</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 231.84 \n",
       "L 231.84 231.84 \n",
       "L 231.84 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#pd801aece37)\">\n",
       "    <image height=\"218\" id=\"imagebb4502c751\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAC7ElEQVR4nO3dAYrCQBQFwc3i/a88ewIVdNOTyVSdICDNBx/RY4wxfoBT/c5+ANiB0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAg8Jj9AK8cxzH7EaYYY8x+BP6ZiwYBoUFAaBAQGgSEBgGhQUBoEDjGwqPNrjvbtxb+yJflokFAaBAQGgSEBgGhQUBoELj0azLv7Po1tVljPS4aBIQGAaFBQGgQEBoEhAYBoUFg6R1tV+/2Qzvb9bhoEBAaBIQGAaFBQGgQEBoEhAYBO9oT77aoXd+F4zMuGgSEBgGhQUBoEBAaBIQGAaFBwI72oW/e+bLB7cdFg4DQICA0CAgNAkKDgNAg4Ov9CbyCsx8XDQJCg4DQICA0CAgNAkKDgNAgYEd7YuZfI/nbpftx0SAgNAgIDQJCg4DQICA0CAgNAna0D83c2ViPiwYBoUFAaBAQGgSEBgGhQUBoELCjneTVznb2xuZ3Ia/HRYOA0CAgNAgIDQJCg4DQICA0CBzD6HI5drb7cdEgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQI+Lm5C/KXUPfjokFAaBAQGgSEBgGhQUBoEBAaBOxoC/Jzcetx0SAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAg8AfKYTe5gnqUXQAAAABJRU5ErkJggg==\" y=\"-6.64\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pd801aece37\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img( partial_removal_img(train_set[1], fraction = .4, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2219fd8-38fa-4f57-b98b-0bb454d47831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b5a9df-eef7-4271-aa6b-eb046940b2db",
   "metadata": {},
   "source": [
    "### 2. MPS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1c4b2-a5a1-4021-81f0-c897771c5caf",
   "metadata": {},
   "source": [
    "1. Create an MPS network\n",
    "2. Canonicalize towards the second tensor\n",
    "3. Rename indexes (in a readable form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215aa3e1-8f89-4aea-b99f-e04bbb2a9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toymps = initialize_mps(Ldim=10, bdim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e014fe-ee0e-41ce-9f3e-49184cb9caef",
   "metadata": {},
   "source": [
    "Inspect shape/canonicalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5736ecd-6731-4ba0-bc35-9082edd20895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2 10 10 10 10 10 8 4 2 \n",
      ">─●──<──<──<──<──<─<─<─<\n",
      "│ │  │  │  │  │  │ │ │ │\n"
     ]
    }
   ],
   "source": [
    "toymps.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca81ae6-41e1-46bb-b5d0-bc9ade08d434",
   "metadata": {},
   "source": [
    "Inspect indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e72f03-fbe5-4773-9d9a-5699e0b95cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=(2, 2), inds=('i0', 'v0'), tags=oset(['I0'])),\n",
       " Tensor(shape=(2, 10, 2), inds=('i0', 'i1', 'v1'), tags=oset(['I1'])),\n",
       " Tensor(shape=(10, 10, 2), inds=('i1', 'i2', 'v2'), tags=oset(['I2'])),\n",
       " Tensor(shape=(10, 10, 2), inds=('i2', 'i3', 'v3'), tags=oset(['I3'])),\n",
       " Tensor(shape=(10, 10, 2), inds=('i3', 'i4', 'v4'), tags=oset(['I4'])),\n",
       " Tensor(shape=(10, 10, 2), inds=('i4', 'i5', 'v5'), tags=oset(['I5'])),\n",
       " Tensor(shape=(10, 8, 2), inds=('i5', 'i6', 'v6'), tags=oset(['I6'])),\n",
       " Tensor(shape=(8, 4, 2), inds=('i6', 'i7', 'v7'), tags=oset(['I7'])),\n",
       " Tensor(shape=(4, 2, 2), inds=('i7', 'i9', 'v8'), tags=oset(['I8'])),\n",
       " Tensor(shape=(2, 2), inds=('i9', 'v9'), tags=oset(['I9'])))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toymps.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095c0fb-521c-4f37-ad6d-657fb6355ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d8954f-8ae1-4400-b2ec-9164d0d571af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps = initialize_mps(bdim=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b95c4-4850-40c4-9e31-b31d30942bbb",
   "metadata": {},
   "source": [
    "I developed two forms to compute the contraction of the mps and an image \n",
    "\n",
    "namely psi(v)\n",
    "\n",
    "1. (SLOW) actually creates the network of the image and contract it \n",
    "2. einsums\n",
    "\n",
    "the two methods outputs the same result, but the second is way faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce70cb67-c079-47e5-8b2f-dacb65ae1564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 s, sys: 0 ns, total: 2.12 s\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "slow_psi = quimb_transform_img2state(train_set[0]) @ mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2af27cd2-172a-4288-82e7-0c1c3bf2b6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 389 µs, total: 11.9 ms\n",
      "Wall time: 10.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "fast_psi = computepsi(mps, train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf6be1-0008-41fd-b0c7-415b1422db98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba33270c-4da6-4be9-8833-415afd267603",
   "metadata": {},
   "source": [
    "### 3. Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2237dff-5f55-4d6e-933f-a7c73aac5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = train_set[:10]\n",
    "mps = initialize_mps(bdim=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b457af54-92e2-46f4-97c1-5a366a42ae81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6108704630728648e-248"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute probability of the first image of the training set of the untrained network\n",
    "computepsi(mps,imgs[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ce80a0-8169-4302-b8c9-f47f316c06ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc5b7cd32134f33ab5b46fc45cfb0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_epoch(mps, imgs, 1, 0.08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437a4d4-cbd8-407c-a760-ff88923f3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU CAN GET PROBABILITIES MORE THAN ONE, WE NEED TO RE-NORMALIZE THE MPS\n",
    "mps = mps / np.sqrt(mps @ mps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "357b28cd-34a8-4157-ae58-e5315dd7c9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7133523167775713e-05"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute probability of the first image of the training set of the trained network\n",
    "computepsi(mps,imgs[0])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7c0eab0-8fae-4e88-a00f-95006eb11ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.290783613279514e-256"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute probability of random noise from the trained network\n",
    "computepsi(mps,np.random.randint(0,2,(784)) )**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f0feb5b-0e73-4360-b222-f5851b2ad4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.446927245580927"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeNLL(mps, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ccdb3-1633-4973-9bd7-8e1ea1b463b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
